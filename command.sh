module load miniconda
conda activate xdecoder

# Set LD_LIBRARY_PATH
export LD_LIBRARY_PATH="$CONDA_PREFIX/lib:$LD_LIBRARY_PATH"
export WANDB_KEY="a9007bbf2af8533987785004be9fae23e52af2f5"
export QUALCOMM_AI_HUB_KEY="44165a068eebd71635bbb8e9198756c50e392b02"

# CUDA_VISIBLE_DEVICES=0,1 mpirun -n 2 
# works with baseline model and FFN layer replacement
python entry.py train \
    --conf_files configs/xdecoder/focalt_unicl_lang_swiGLUDYT.yaml \
    --overrides \
    FP16 True \
    PORT 36874 \
    SOLVER.MAX_NUM_EPOCHS 2 \
    COCO.INPUT.IMAGE_SIZE 512 \
    MODEL.DECODER.HIDDEN_DIM 512 \
    MODEL.ENCODER.CONVS_DIM 512 \
    MODEL.ENCODER.MASK_DIM 512 \
    MODEL.DECODER.CAPTIONING.ENABLED False \
    MODEL.DECODER.RETRIEVAL.ENABLED False \
    MODEL.DECODER.GROUNDING.ENABLED True \
    MODEL.DECODER.CAPTIONING_WEIGHT 4 \
    MODEL.DECODER.RETRIEVAL_WEIGHT 4 \
    MODEL.DECODER.TOP_CAPTIONING_LAYERS 2 \
    MODEL.DECODER.TOP_RETRIEVAL_LAYERS 2 \
    MODEL.DECODER.TOP_GROUNDING_LAYERS 3 \
    MODEL.DECODER.GROUNDING.TEXT_WEIGHT 1.0 \
    MODEL.DECODER.GROUNDING.CLASS_WEIGHT 0.5 \
    COCO.TEST.BATCH_SIZE_TOTAL 8 \
    COCO.TRAIN.BATCH_SIZE_TOTAL 8 \
    COCO.TRAIN.BATCH_SIZE_PER_GPU 8 \
    VLP.TEST.BATCH_SIZE_TOTAL 8 \
    VLP.TRAIN.BATCH_SIZE_TOTAL 8 \
    VLP.TRAIN.BATCH_SIZE_PER_GPU 8 \
    VLP.DATALOADER.NUM_WORKERS 4 \
    ADE20K.TEST.BATCH_SIZE_TOTAL 1 \
    REF.TEST.BATCH_SIZE_TOTAL 1 \
    SOLVER.LR_MULTIPLIER.lang_encoder 0.1 \
    WEIGHT True \
    SAVE_DIR ./outputs
